{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import All the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:07:14.518883Z",
     "iopub.status.busy": "2024-10-05T18:07:14.517960Z",
     "iopub.status.idle": "2024-10-05T18:07:26.887499Z",
     "shell.execute_reply": "2024-10-05T18:07:26.886536Z",
     "shell.execute_reply.started": "2024-10-05T18:07:14.518806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, ReLU, BatchNormalization, Bidirectional, LSTM, TimeDistributed, Reshape, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Low Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T18:07:26.890055Z",
     "iopub.status.busy": "2024-10-05T18:07:26.889366Z",
     "iopub.status.idle": "2024-10-05T18:07:35.214999Z",
     "shell.execute_reply": "2024-10-05T18:07:35.213500Z",
     "shell.execute_reply.started": "2024-10-05T18:07:26.890009Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input and output paths\n",
    "input_folder = r'/kaggle/input/librispeech-clean/LibriSpeech/test-clean'\n",
    "output_folder = r'/kaggle/working/lowfreq'\n",
    "\n",
    "# List of target sampling rates (e.g., 1000 Hz, 2000 Hz, 4000 Hz, 8000 Hz)\n",
    "target_sample_rates = [2000, 4000, 8000]\n",
    "  -\n",
    "# 0Walk through all files in the input folder\n",
    "for0. \n",
    "root, _, files in os.walk(input_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.flac'):\n",
    "            # Construct full file path\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            # Load the audio file\n",
    "            audio_data, original_sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "            # Iterate through each target sampling rate\n",
    "            for target_sr in target_sample_rates:\n",
    "                # Resample the audio to the target sampling rate\n",
    "                resampled_audio = librosa.resample(audio_data, orig_sr=original_sr, target_sr=target_sr)\n",
    "\n",
    "                # Create the output file path, preserving the folder structure\n",
    "                relative_path = os.path.relpath(root, input_folder)\n",
    "                output_path = os.path.join(output_folder, f\"{target_sr}Hz\", relative_path)\n",
    "                os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "                # Save the resampled audio as a .wav file\n",
    "                output_file = os.path.join(output_path, os.path.splitext(file)[0] + f'_{target_sr}Hz.wav')\n",
    "                sf.write(output_file, resampled_audio, target_sr)\n",
    "\n",
    "                # Print progress update (carriage return)\n",
    "                print(f\"\\rResampled audio saved at {output_file}\", end='')\n",
    "\n",
    "print(\"\\nAll low-frequency audio conversion completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Both High and Low-Resolution Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-05T18:07:35.215893Z",
     "iopub.status.idle": "2024-10-05T18:07:35.216269Z",
     "shell.execute_reply": "2024-10-05T18:07:35.216107Z",
     "shell.execute_reply.started": "2024-10-05T18:07:35.216088Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Input and output paths for low-frequency feature extraction\n",
    "input_folder_lr = r'/kaggle/working/lowfreq'\n",
    "output_folder_lr = r'/kaggle/working/features/low_res'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder_lr, exist_ok=True)\n",
    "\n",
    "# Function to calculate and save Mel-spectrogram\n",
    "def save_mel_spectrogram(audio_data, sr, output_file):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio_data, sr=sr, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    np.save(output_file, mel_spec_db)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mel_spec_db, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.savefig(output_file.replace('.npy', '.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Function to calculate and save MFCCs\n",
    "def save_mfcc(audio_data, sr, output_file):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)\n",
    "    np.save(output_file, mfccs)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(output_file.replace('.npy', '.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Walk through low-frequency files to extract features\n",
    "for root, _, files in os.walk(input_folder_lr):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            audio_data, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "            # Choose either Mel-spectrogram or MFCC\n",
    "            use_mfcc = True  # Change to False if you want to use Mel-spectrograms\n",
    "\n",
    "            output_file = os.path.join(output_folder_lr, os.path.splitext(file)[0] + '.npy')\n",
    "            if use_mfcc:\n",
    "                save_mfcc(audio_data, sr, output_file)\n",
    "            else:\n",
    "                save_mel_spectrogram(audio_data, sr, output_file)\n",
    "\n",
    "            # Print progress update (carriage return)\n",
    "            print(f\"\\rExtracted {'MFCC' if use_mfcc else 'Mel-spectrogram'} for low-res {file}\", end='')\n",
    "\n",
    "print(\"\\nAll low-resolution feature extraction completed successfully.\")\n",
    "\n",
    "# Input and output paths for high-resolution feature extraction\n",
    "input_folder_hr = r'/kaggle/input/librispeech-clean/LibriSpeech/test-clean'  # Original dataset path\n",
    "output_folder_hr = r'/kaggle/working/features/high_res'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder_hr, exist_ok=True)\n",
    "\n",
    "# Walk through all files in the original input folder for high-resolution feature extraction\n",
    "for root, _, files in os.walk(input_folder_hr):\n",
    "    for file in files:\n",
    "        if file.endswith('.flac'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            audio_data, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "            output_file = os.path.join(output_folder_hr, os.path.splitext(file)[0] + '.npy')\n",
    "            if use_mfcc:\n",
    "                save_mfcc(audio_data, sr, output_file)\n",
    "            else:\n",
    "                save_mel_spectrogram(audio_data, sr, output_file)\n",
    "\n",
    "            # Print progress update (carriage return)\n",
    "            print(f\"\\rExtracted {'MFCC' if use_mfcc else 'Mel-spectrogram'} for high-res {file}\", end='')\n",
    "\n",
    "print(\"\\nAll high-resolution feature extraction completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Normalize and Standardize the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-05T18:07:35.218060Z",
     "iopub.status.idle": "2024-10-05T18:07:35.218417Z",
     "shell.execute_reply": "2024-10-05T18:07:35.218262Z",
     "shell.execute_reply.started": "2024-10-05T18:07:35.218244Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Input and output paths for normalized features\n",
    "input_folder_lr = r'/kaggle/working/features/low_res'  # Low-resolution features path\n",
    "input_folder_hr = r'/kaggle/working/features/high_res'  # High-resolution features path\n",
    "output_folder_lr = r'/kaggle/working/normalized_features/low_res'  # Normalized low-res features output path\n",
    "output_folder_hr = r'/kaggle/working/normalized_features/high_res'  # Normalized high-res features output path\n",
    "\n",
    "# Create the output folders if they don't exist\n",
    "os.makedirs(output_folder_lr, exist_ok=True)\n",
    "os.makedirs(output_folder_hr, exist_ok=True)\n",
    "\n",
    "# Function to normalize the feature data to range [0, 1]\n",
    "def normalize_features(features):\n",
    "    scaler = MinMaxScaler()\n",
    "    return scaler.fit_transform(features)\n",
    "\n",
    "# Function to standardize the feature data (mean=0, std=1)\n",
    "def standardize_features(features):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(features)\n",
    "\n",
    "# Choose whether to normalize or standardize\n",
    "use_standardization = True  # Set to False if you want normalization instead\n",
    "\n",
    "# List of input folders and their corresponding output folders\n",
    "folders = [\n",
    "    (input_folder_lr, output_folder_lr),\n",
    "    (input_folder_hr, output_folder_hr)\n",
    "]\n",
    "\n",
    "# Walk through all .npy files in the input folders\n",
    "for input_folder, output_folder in folders:\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.npy'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                features = np.load(file_path)\n",
    "\n",
    "                # Reshape the feature array if necessary (flatten if it's 2D or 3D)\n",
    "                original_shape = features.shape\n",
    "                if len(features.shape) > 1:\n",
    "                    features = features.reshape(-1, original_shape[-1])\n",
    "\n",
    "                # Normalize or standardize the features\n",
    "                if use_standardization:\n",
    "                    processed_features = standardize_features(features)\n",
    "                else:\n",
    "                    processed_features = normalize_features(features)\n",
    "\n",
    "                # Reshape back to original shape if necessary\n",
    "                processed_features = processed_features.reshape(original_shape)\n",
    "\n",
    "                # Create the output file path, preserving the folder structure\n",
    "                relative_path = os.path.relpath(root, input_folder)\n",
    "                output_path = os.path.join(output_folder, relative_path)\n",
    "                os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "                # Save the normalized or standardized features as a .npy file\n",
    "                output_file = os.path.join(output_path, file)\n",
    "                np.save(output_file, processed_features)\n",
    "\n",
    "                # Print progress update (carriage return)\n",
    "                print(f\"\\rProcessed features for {file}\", end='')\n",
    "\n",
    "print(\"\\nAll feature normalization/standardization completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train Dataset for Super-Resolution Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-05T18:07:35.219845Z",
     "iopub.status.idle": "2024-10-05T18:07:35.220323Z",
     "shell.execute_reply": "2024-10-05T18:07:35.220098Z",
     "shell.execute_reply.started": "2024-10-05T18:07:35.220075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Paths to folders containing extracted low-res and high-res features\n",
    "low_res_features_path = r'/kaggle/working/normalized_features/low_res'  # Replace with actual path\n",
    "high_res_features_path = r'/kaggle/working/normalized_features/high_res'  # Replace with actual path\n",
    "\n",
    "# Load features\n",
    "def load_feature(file_path):\n",
    "    # Assuming the features are saved as numpy arrays (.npy files)\n",
    "    return np.load(file_path)\n",
    "\n",
    "# Get list of all feature files (ensure low-res and high-res are in matching order)\n",
    "low_res_files = sorted([f'{low_res_features_path}/{file}' for file in os.listdir(low_res_features_path)])\n",
    "high_res_files = sorted([f'{high_res_features_path}/{file}' for file in os.listdir(high_res_features_path)])\n",
    "\n",
    "# Function to load and pair low-res and high-res features\n",
    "def load_data(low_res_file, high_res_file):\n",
    "    low_res_mfcc = load_feature(low_res_file)\n",
    "    high_res_mfcc = load_feature(high_res_file)\n",
    "    return low_res_mfcc, high_res_mfcc\n",
    "\n",
    "# Create a TensorFlow dataset from the low-res and high-res feature pairs\n",
    "def create_dataset(low_res_files, high_res_files, batch_size=16):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((low_res_files, high_res_files))\n",
    "\n",
    "    dataset = dataset.map(lambda low_res_file, high_res_file: tf.py_function(\n",
    "        func=lambda low_res_file, high_res_file: load_data(low_res_file.numpy(), high_res_file.numpy()), \n",
    "        inp=[low_res_file, high_res_file], \n",
    "        Tout=(tf.float32, tf.float32)),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Create the training dataset\n",
    "train_dataset = create_dataset(low_res_files, high_res_files, batch_size=16)\n",
    "\n",
    "sample_feature = np.load(low_res_files[0])  # Load a sample feature\n",
    "print(sample_feature.shape)  # Print the shape of the feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design the Super-Resolution Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-05T18:07:35.222175Z",
     "iopub.status.idle": "2024-10-05T18:07:35.222519Z",
     "shell.execute_reply": "2024-10-05T18:07:35.222365Z",
     "shell.execute_reply.started": "2024-10-05T18:07:35.222347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CNN + RNN (LSTM) Super-Resolution Network\n",
    "def build_cnn_rnn_super_resolution(input_shape):\n",
    "    inputs = Input(shape=input_shape)  # Input shape will be (time_steps, frequency_bins, channels)\n",
    "    \n",
    "    # CNN Layers\n",
    "    x = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Upsampling layers\n",
    "    x = Conv2DTranspose(128, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2DTranspose(64, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Reshape for RNN input\n",
    "    x = Reshape((x.shape[1], x.shape[2] * x.shape[3]))(x)\n",
    "\n",
    "    # Add Bidirectional LSTM for temporal modeling\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "\n",
    "    # Reshape back to CNN's dimensions\n",
    "    x = Reshape((input_shape[0], input_shape[1], 1))(x)\n",
    "\n",
    "    # Final output layer\n",
    "    outputs = Conv2D(1, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='linear')(x)\n",
    "\n",
    "    # Build the model\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Example input shape (time_steps, frequency_bins, channels)\n",
    "input_shape = (128, 64, 1)  # Adjust based on your feature size\n",
    "\n",
    "# Build the model\n",
    "model = build_cnn_rnn_super_resolution(input_shape)\n",
    "\n",
    "# Compile the model with MSE loss and Adam optimizer\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='mse')\n",
    "\n",
    "# Model summary to check the architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-05T18:07:35.224354Z",
     "iopub.status.idle": "2024-10-05T18:07:35.225081Z",
     "shell.execute_reply": "2024-10-05T18:07:35.224845Z",
     "shell.execute_reply.started": "2024-10-05T18:07:35.224801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,   # Low-res and high-res training pairs (low_res_mfcc, high_res_mfcc)\n",
    "    epochs=100,      # Adjust the number of epochs as needed\n",
    "    validation_data=val_dataset,  # You need to create a validation dataset similarly\n",
    "    batch_size=16,   # Adjust batch size based on your hardware\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]  # Early stopping for efficiency\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1670098,
     "sourceId": 2739456,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
